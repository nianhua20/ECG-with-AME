# Project Overview

This project originates from the Kaggle notebook: [PyTorch RNN ECG5000](https://www.kaggle.com/code/alfredkondoro/pytorch-rnn-ecg5000). 

The primary objective of this project is to investigate whether the **AME module** can be extended to work with modalities beyond the typical language, audio, and vision modalities commonly used in Multimodal Sentiment Analysis (MSA). To achieve this, we modified and tested the original project.

## How to Run
To execute the project, simply run the `main.py` file.

## Results
With the integration of the AME module, the test accuracy improved from **98.27% to 99.33%**. These results demonstrate that the AME module effectively enhances physiological signal features through **adaptive frequency feature fusion**, showcasing its adaptability to a broader range of multimodal tasks beyond traditional modalities.
